{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schizophrenia classification problem\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold,GridSearchCV\n",
    "import zipapp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c13feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dfaf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_files=glob('extraction_directory/*.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bf81cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(edf_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5bcdd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edf_files='k/extraction_directory/h03.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3eaa8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_file_path=[i for i in edf_files if 'h' in i.split('/')[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821220b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_file_path=[i for i in edf_files if 's' in i.split('/')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73ee8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def read_Data(file_path):\n",
    "    # Load the EEG data from the EDF file with preload=True\n",
    "    data=mne.io.read_raw_edf(file_path,preload=True)\n",
    "    # Set EEG reference (if not already set)\n",
    "    data.set_eeg_reference()\n",
    "    # Apply a bandpass filter from 0.5 Hz to 45 Hz\n",
    "    data.filter(l_freq=0.5,h_freq=45)\n",
    "    # Apply a notch filter to remove power line noise (50 Hz)\n",
    "    data.notch_filter(freqs=50)\n",
    "    # Create epochs with a fixed length of 5 seconds and 1-second overlap\n",
    "    epochs=mne.make_fixed_length_epochs(data,duration=5,overlap=1)\n",
    "    # Load data into memory (necessary for ICA)                                   )\n",
    "    epochs.load_data()\n",
    "    # Apply Independent Component Analysis (ICA) for artifact removal                                    \n",
    "    ica = mne.preprocessing.ICA(n_components=5, random_state=97, max_iter=800)\n",
    "    ica.fit(epochs)\n",
    "    epochs = ica.apply(epochs)\n",
    "    # Reject epochs with high amplitude (adjust the threshold as needed)\n",
    "    epochs.drop_bad(reject={'eeg': 100e-6})                                   \n",
    "     \n",
    "    #Baseline correction (adjust the baseline period as needed)\n",
    "    epochs.apply_baseline((0, 4.996))  # Correct the baseline to the period from -0.5 to 0 seconds\n",
    "    bad_channels = epochs.info['bads']\n",
    "    # Reset bad channels (if desired)\n",
    "    epochs.info['bads'] = []\n",
    "     # Get the EEG data as a NumPy array  \n",
    "    # Spatial Filtering (e.g., surface Laplacian)\n",
    "    epochs.set_eeg_reference('average', projection=False)\n",
    "        \n",
    "        # Montage Selection (replace with your specific montage)\n",
    "    #montage = mne.channels.read_custom_montage(data)\n",
    "    #epochs.set_montage(montage)\n",
    "        \n",
    "        # Decimation (downsampling to a lower sampling rate)\n",
    "    epochs.resample(100)  # Replace '100' with your desired new sampling rate\n",
    "            \n",
    "    array=epochs.get_data()\n",
    "    \n",
    "    \n",
    "    return array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b4c8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/pawan/Downloads/Ghanim_machine_learning/data_code/extraction_directory/h03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 227499  =      0.000 ...   909.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "227 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 227 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Fitting ICA to data using 19 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 5 components\n",
      "Fitting ICA took 1.2s.\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (5 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 19 PCA components\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'T6', 'Fp1', 'F7', 'T5', 'O1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'T6', 'O2', 'Fp1', 'F7', 'T5', 'O1', 'P4', 'F3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'O2', 'Fp1', 'T5', 'O1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'T6', 'O2', 'Fp1', 'F7', 'T5', 'F3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F8', 'T6', 'O2', 'Fp1', 'F7', 'T3', 'T5', 'O1', 'F4', 'F3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F8', 'Fp1', 'F7', 'T5']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1', 'F7']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F8', 'Fp1', 'F7', 'T3', 'F3', 'C3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F8', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F8', 'Fp1', 'F7']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['F7', 'T3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1', 'F3']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'Fp1']\n",
      "26 bad epochs dropped\n",
      "Applying baseline correction (mode: mean)\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "file_path=healthy_file_path[0]\n",
    "sample_data=read_Data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e747d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 19, 500)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffbc4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "control_epochs_array=[read_Data(i) for i in healthy_file_path]\n",
    "patient_epochs_array=[read_Data(i) for i in patient_file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "090b2849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating labels\n",
    "control_epoch_labels=[len(i)*[0] for i in control_epochs_array]\n",
    "patient_epoch_labels=[len(i)*[1] for i in patient_epochs_array]\n",
    "len(control_epoch_labels),len(patient_epoch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae406b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=control_epochs_array+patient_epochs_array\n",
    "label_list=control_epoch_labels+patient_epoch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae7b54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group list\n",
    "group_list=[[i]*len(j) for i,j in enumerate(data_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c61b5652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9f398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94f67cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 19, 500) (5482,) (5482,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the list to array\n",
    "data_array=np.vstack(data_list)\n",
    "label_array=np.hstack(label_list)\n",
    "group_array=np.hstack(group_list)\n",
    "print(data_array.shape,label_array.shape,group_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d8112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now\n",
    "# Extract feature from the raw data\n",
    "from scipy import stats\n",
    "def mean(x):\n",
    "    return np.mean(x,axis=-1)\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "def var(x):\n",
    "    return np.var(x,axis=-1)\n",
    "def minim(x):\n",
    "    return np.min(x,axis=-1)\n",
    "def maxim(x):\n",
    "    return np.max(x,axis=-1)\n",
    "def argminim(x):\n",
    "    return np.argmin(x,axis=-1)\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "def sqrt(x):\n",
    "    return np.sqrt(np.mean(x ** 2, axis=-1))\n",
    "def abs_diff_sigma(x):\n",
    "    return np.sum(np.abs(np.diff(x,axis=-1)),axis=-1)\n",
    "def skew(x):\n",
    "    return stats.skew(x,axis=-1)\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x,axis=-1)\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x),std(x),ptp(x),var(x),minim(x),maxim(x),argminim(x),\n",
    " argmaxim(x),sqrt(x),abs_diff_sigma(x),skew(x),\n",
    "    kurtosis(x)),axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a976b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4ab39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5482, 228)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array=np.array(features)\n",
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea7515e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=GroupKFold(n_splits=5),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=12, param_grid={&#x27;clf__C&#x27;: [0.1, 0.5, 0.7, 1, 3, 5, 7]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=GroupKFold(n_splits=5),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=12, param_grid={&#x27;clf__C&#x27;: [0.1, 0.5, 0.7, 1, 3, 5, 7]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=GroupKFold(n_splits=5),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=12, param_grid={'clf__C': [0.1, 0.5, 0.7, 1, 3, 5, 7]})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "clf=LogisticRegression(max_iter=1000)\n",
    "gkf=GroupKFold(5)\n",
    "pipe=Pipeline([('scaler',StandardScaler()),('clf',clf)])\n",
    "param_grid={'clf__C':[.1,.5,.7,1,3,5,7]}\n",
    "gscv=GridSearchCV(pipe,param_grid,cv=gkf,n_jobs=12)\n",
    "gscv.fit(features_array,label_array,groups=group_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1578a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7265968617950622"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ce967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
